{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ada2f1",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b185ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing necessary libs\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65cbb7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-2.791855</td>\n",
       "      <td>-0.327771</td>\n",
       "      <td>1.641750</td>\n",
       "      <td>1.767473</td>\n",
       "      <td>-0.136588</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>-0.422911</td>\n",
       "      <td>-1.907107</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151663</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>1.020586</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>-0.235557</td>\n",
       "      <td>-0.164778</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>15.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.0</td>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.0</td>\n",
       "      <td>-5.401258</td>\n",
       "      <td>-5.450148</td>\n",
       "      <td>1.186305</td>\n",
       "      <td>1.736239</td>\n",
       "      <td>3.049106</td>\n",
       "      <td>-1.763406</td>\n",
       "      <td>-1.559738</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503600</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>2.458589</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>-0.481631</td>\n",
       "      <td>-0.621272</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.949594</td>\n",
       "      <td>46.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.492936</td>\n",
       "      <td>-1.029346</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-1.555434</td>\n",
       "      <td>-0.720961</td>\n",
       "      <td>-1.080664</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-1.978682</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.175074</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0    0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1    0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2    1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3    1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4    2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "5    2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
       "6    4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708   \n",
       "7    7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118   \n",
       "8    7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818   \n",
       "9    9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
       "10  10.0  1.449044 -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n",
       "11  10.0  0.384978  0.616109 -0.874300 -0.094019  2.924584  3.317027   \n",
       "12  10.0  1.249999 -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n",
       "13  11.0  1.069374  0.287722  0.828613  2.712520 -0.178398  0.337544   \n",
       "14  12.0 -2.791855 -0.327771  1.641750  1.767473 -0.136588  0.807596   \n",
       "15  12.0 -0.752417  0.345485  2.057323 -1.468643 -1.158394 -0.077850   \n",
       "16  12.0  1.103215 -0.040296  1.267332  1.289091 -0.735997  0.288069   \n",
       "17  13.0 -0.436905  0.918966  0.924591 -0.727219  0.915679 -0.127867   \n",
       "18  14.0 -5.401258 -5.450148  1.186305  1.736239  3.049106 -1.763406   \n",
       "19  15.0  1.492936 -1.029346  0.454795 -1.438026 -1.555434 -0.720961   \n",
       "\n",
       "          V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0   0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2   0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3   0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4   0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "5   0.476201  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427   \n",
       "6  -0.005159  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055   \n",
       "7   1.120631 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709   \n",
       "8   0.370145  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592   \n",
       "9   0.651583  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050   \n",
       "10 -1.423236  0.048456 -1.720408  ... -0.009302  0.313894  0.027740  0.500512   \n",
       "11  0.470455  0.538247 -0.558895  ...  0.049924  0.238422  0.009130  0.996710   \n",
       "12 -0.689405 -0.227487 -2.094011  ... -0.231809 -0.483285  0.084668  0.392831   \n",
       "13 -0.096717  0.115982 -0.221083  ... -0.036876  0.074412 -0.071407  0.104744   \n",
       "14 -0.422911 -1.907107  0.755713  ...  1.151663  0.222182  1.020586  0.028317   \n",
       "15 -0.608581  0.003603 -0.436167  ...  0.499625  1.353650 -0.256573 -0.065084   \n",
       "16 -0.586057  0.189380  0.782333  ... -0.024612  0.196002  0.013802  0.103758   \n",
       "17  0.707642  0.087962 -0.665271  ... -0.194796 -0.672638 -0.156858 -0.888386   \n",
       "18 -1.559738  0.160842  1.233090  ... -0.503600  0.984460  2.458589  0.042119   \n",
       "19 -1.080664 -0.053127 -1.978682  ... -0.177650 -0.175074  0.040002  0.295814   \n",
       "\n",
       "         V25       V26       V27       V28  Amount  Class  \n",
       "0   0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1   0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2  -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3   0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "5  -0.232794  0.105915  0.253844  0.081080    3.67      0  \n",
       "6   0.750137 -0.257237  0.034507  0.005168    4.99      0  \n",
       "7  -0.415267 -0.051634 -1.206921 -1.085339   40.80      0  \n",
       "8   0.373205 -0.384157  0.011747  0.142404   93.20      0  \n",
       "9  -0.069733  0.094199  0.246219  0.083076    3.68      0  \n",
       "10  0.251367 -0.129478  0.042850  0.016253    7.80      0  \n",
       "11 -0.767315 -0.492208  0.042472 -0.054337    9.99      0  \n",
       "12  0.161135 -0.354990  0.026416  0.042422  121.50      0  \n",
       "13  0.548265  0.104094  0.021491  0.021293   27.50      0  \n",
       "14 -0.232746 -0.235557 -0.164778 -0.030154   58.80      0  \n",
       "15 -0.039124 -0.087086 -0.180998  0.129394   15.99      0  \n",
       "16  0.364298 -0.382261  0.092809  0.037051   12.99      0  \n",
       "17 -0.342413 -0.049027  0.079692  0.131024    0.89      0  \n",
       "18 -0.481631 -0.621272  0.392053  0.949594   46.80      0  \n",
       "19  0.332931 -0.220385  0.022298  0.007602    5.00      0  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading data\n",
    "data = pd.read_csv(\"creditcard.csv\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4ef5e2",
   "metadata": {},
   "source": [
    "# About Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be166265",
   "metadata": {},
   "source": [
    "This dataset presents transactions that occurred in two days, where we have 492 frauds out of\n",
    "284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account \n",
    "for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation.\n",
    "Unfortunately, due to confidentiality issues, we cannot provide the original features and more \n",
    "background information about the data. Features V1, V2, … V28 are the principal components obtained \n",
    "with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. \n",
    "Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the\n",
    "dataset. The feature 'Amount' is the transaction Amount, this feature can be used for \n",
    "example-dependant cost-sensitive learning. Feature 'Class' is the response variable and it takes \n",
    "value 1 in case of fraud and 0 otherwise.\n",
    "It is downloaded from kaggle - https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6347ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69b720fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1da2741c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c521d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target\n",
    "X = data.drop(\"Class\", axis=1)\n",
    "y = data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b4f7a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe5f42",
   "metadata": {},
   "source": [
    "# Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a33cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature normalization\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c78b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the normalized data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d317e4",
   "metadata": {},
   "source": [
    "# Handling class imbalance issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd60bcc2",
   "metadata": {},
   "source": [
    "Undersampling: Undersampling involves reducing the number of instances in the majority class \n",
    "to balance it with the minority class. The idea is to randomly remove examples from the majority \n",
    "class until the dataset becomes more balanced. This approach helps prevent the classifier from being \n",
    "biased towards the majority class due to its overwhelming representation in the dataset. \n",
    "However, undersampling may discard potentially useful data, leading to the loss of information.\n",
    "\n",
    "Oversampling: Oversampling involves increasing the number of instances in the minority class to \n",
    "balance it with the majority class. The goal is to create synthetic examples that resemble the\n",
    "minority class by replicating or generating new samples. Popular oversampling techniques include \n",
    "duplication (replicating existing samples), synthetic minority oversampling technique (SMOTE), and a\n",
    "daptive synthetic sampling (ADASYN). These methods aim to create a more balanced dataset by providing\n",
    "the classifier with sufficient information from the minority class. However, oversampling may introduce synthetic noise or lead to overfitting if not carefully implemented.\n",
    "\n",
    "\n",
    "Both undersampling and oversampling techniques aim to mitigate the issues caused by class imbalance,\n",
    "enabling the classifier to learn from both classes effectively. The choice between these techniques \n",
    "depends on the specific dataset and problem at hand. It is important to experiment and evaluate the \n",
    "performance of different approaches to determine the most suitable method for a particular scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d171dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance using SMOTE oversampling\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e071eda9",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e37e9d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Logistic Regression\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic = logistic_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b96c1262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Performance:\n",
      "Accuracy: 0.9879802909542034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     85307\n",
      "           1       0.11      0.93      0.20       136\n",
      "\n",
      "    accuracy                           0.99     85443\n",
      "   macro avg       0.56      0.96      0.60     85443\n",
      "weighted avg       1.00      0.99      0.99     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logistic))\n",
    "print(classification_report(y_test, y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74de6e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7e9d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Performance:\n",
      "Accuracy: 0.9995786664794073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.85      0.89      0.87       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.93      0.94      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
